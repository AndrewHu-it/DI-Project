Resources: We can draw mostly out of my AI/ML book for next year, as well as relevant advances. 


https://www.amazon.co.uk/Artificial-Intelligence-Modern-Approach-Global/dp/1292153962


“The DQN AI system of Google DeepMind can accomplish a slightly broader range of goals: it can play dozens of different vintage Atari computer games at human level or better.”

Excerpt From
Life 3.0
Max Tegmark
This material may be protected by copyright.

Moravec’s paradox,

“Computers are universal machines, their potential extends uniformly over a boundless expanse of tasks. Human potentials, on the other hand, are strong in areas long important for survival, but weak in things far removed. Imagine a “landscape of human competence,” having lowlands with labels like “arithmetic” and “rote memorization,” foothills like “theorem proving” and “chess playing,” and high mountain peaks labeled “locomotion,” “hand-eye coordination” and “social interaction.” Advancing computer performance is like water slowly flooding the landscape. A half century ago it began to drown the lowlands, driving out human calculators and record clerks, but leaving most of us dry. Now the flood has reached the foothills, and our outposts there are contemplating retreat. We feel safe on our peaks, but, at the present rate, those too will be submerged within another half century. I propose that we build Arks as that day nears, and adopt a seafaring life”

“Hans Moravec, “When Will Computer Hardware Match the Human Brain?” Journal of Evolution and Technology (1998), vol. 1.”

Excerpt From
Life 3.0
Max Tegmark
This material may be protected by copyright.


***Here, it might be a good idea to show how certain principles are inspired by biologically evolved modes and methods for learning and parsing the world.*** 

Dopamine is TDL (Temporal Difference Learning):
>“The dopamine responses that Schultz found in monkeys aligned exactly with Sutton’s temporal difference learning signal. Dopamine neurons in Schultz’s monkeys got excited by predictive cues because these cues led to an increase in predicted future rewards (a positive temporal difference); dopamine neurons were unaffected by the delivery of an expected reward because there was no change in predicted future reward (no temporal difference); and dopamine-neuron activity decreased when expected rewards were omitted because there was a decrease in predicted future rewards (a negative temporal difference).”
(Brief History Of Intelligence)


EX: Convolutional Neural nets, picking up features of a particular image is analogous to how biological NNs do it. 
		Kunihiko Fukushima, the guy who invented CNNs, even got his inspiration from biological systems

**But there are also many examples of methods of learning that do not have any evolved mechanism or analogous process in nature: **
- supervised learning (nothing biological about supervised learning)



Biological Memory vs Computer Memory: 
B: content addressable memory (subset of memory --> full thing)
C: Register addressable memory (register --> automatically gives full thing)
- This needs to be distinguished from memory on the basic level of the computers operating and the memory that can be stored in the artificial neural network.


***Catastrophic interference*** --> this only happens in neural networks that are trying to encode memory. 


